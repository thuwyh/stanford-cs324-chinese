---
layout: page
parent: è®²ä¹‰
title: å¯¼è®º
nav_order: 1
usemathjax: true
---
$$
\newcommand{\sV}{\mathcal{V}}
\newcommand{\nl}[1]{\textsf{#1}}
\newcommand{\generate}[1]{\stackrel{#1}{\rightsquigarrow}}
$$

æ¬¢è¿æ¥åˆ°CS324ï¼è¿™æ˜¯ä¸€é—¨å…³äºç†è§£å’Œå¼€å‘**å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹**çš„æ–°è¯¾ç¨‹ã€‚



1. [ä»€ä¹ˆæ˜¯è¯­è¨€æ¨¡å‹ï¼Ÿ](#ä»€ä¹ˆæ˜¯è¯­è¨€æ¨¡å‹ï¼Ÿ)
1. [è¯­è¨€æ¨¡å‹ç®€å²](#è¯­è¨€æ¨¡å‹ç®€å²)
1. [ä¸ºä»€ä¹ˆä¼šæœ‰è¿™é—¨è¯¾ç¨‹ï¼Ÿ](#ä¸ºä»€ä¹ˆä¼šæœ‰è¿™é—¨è¯¾ç¨‹)
1. [è¿™é—¨è¯¾ç¨‹çš„ç»“æ„](#è¿™é—¨è¯¾ç¨‹çš„ç»“æ„)

## ä»€ä¹ˆæ˜¯è¯­è¨€æ¨¡å‹ï¼Ÿ

è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰çš„ç»å…¸å®šä¹‰æ˜¯å¯¹tokenåºåˆ—çš„æ¦‚ç‡åˆ†å¸ƒã€‚
å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«ä¸€ç»„tokençš„**è¯æ±‡è¡¨** $$\sV$$ã€‚

ä¸€ä¸ªè¯­è¨€æ¨¡å‹$$p$$ä¸ºæ¯ä¸ªtokenåºåˆ—$$x_1, \dots, x_L \in \sV$$åˆ†é…æ¦‚ç‡ï¼ˆä»‹äº0å’Œ1ä¹‹é—´ï¼‰ã€‚

$$p(x_1, \dots, x_L).$$


æ¦‚ç‡ç›´è§‚åœ°å‘Šè¯‰æˆ‘ä»¬ä¸€ä¸ªè®°å·åºåˆ—çš„â€œå¥½åâ€ç¨‹åº¦ã€‚
ä¾‹å¦‚ï¼Œå¦‚æœè¯æ±‡è¡¨æ˜¯$$\sV = \{ \nl{ate}, \nl{ball}, \nl{cheese}, \nl{mouse}, \nl{the} \}$$ï¼Œè¯­è¨€æ¨¡å‹å¯èƒ½ä¼šåˆ†é…ä»¥ä¸‹æ¦‚ç‡å€¼ï¼š
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=%24%7Bprompt%7D&settings=echo_prompt%3A%20true%0Amax_tokens%3A%200&environments=prompt%3A%20%5Bthe%20mouse%20ate%20the%20cheese%2C%20the%20cheese%20ate%20the%20mouse%2C%20mouse%20the%20the%20cheese%20ate%5D)):

$$p(\nl{the}, \nl{mouse}, \nl{ate}, \nl{the}, \nl{cheese}) = 0.02,$$

$$p(\nl{the}, \nl{cheese}, \nl{ate}, \nl{the}, \nl{mouse}) = 0.01,$$

$$p(\nl{mouse}, \nl{the}, \nl{the}, \nl{cheese}, \nl{ate}) = 0.0001.$$


ä»æ•°å­¦ä¸Šè®²ï¼Œè¯­è¨€æ¨¡å‹æ˜¯ä¸€ä¸ªéå¸¸ç®€å•è€Œä¼˜ç¾çš„å¯¹è±¡ã€‚
ä½†è¿™ç§ç®€å•æ€§æ˜¯å…·æœ‰æ¬ºéª—æ€§çš„ï¼šèƒ½å¤Ÿä¸ºæ‰€æœ‰åºåˆ—åˆ†é…ï¼ˆæœ‰æ„ä¹‰çš„ï¼‰æ¦‚ç‡éœ€è¦éå‡¡çš„ï¼ˆä½†æ˜¯*éšå«çš„*ï¼‰è¯­è¨€èƒ½åŠ›å’Œä¸–ç•ŒçŸ¥è¯†ã€‚

ä¾‹å¦‚ï¼Œè¯­è¨€æ¨¡å‹åº”è¯¥éšå«åœ°åˆ†é…éå¸¸ä½çš„æ¦‚ç‡ç»™$$\nl{mouse the the cheese ate}$$ ï¼Œå› ä¸ºè¿™æ˜¯ä¸ç¬¦åˆè¯­æ³•çš„ï¼ˆ**è¯­æ³•çŸ¥è¯†**ï¼‰ã€‚
è¯­è¨€æ¨¡å‹åº”è¯¥éšå«åœ°ä¸º$$\nl{the mouse ate the cheese}$$ åˆ†é…æ¯”$$\nl{the cheese ate the mouse}$$ æ›´é«˜çš„æ¦‚ç‡ï¼Œå› ä¸ºå®ƒæ¶‰åŠåˆ°**ä¸–ç•ŒçŸ¥è¯†**ï¼šä¸¤ä¸ªå¥å­åœ¨å¥æ³•ä¸Šç›¸åŒï¼Œä½†åœ¨è¯­ä¹‰ä¸Šçš„å¯ä¿¡åº¦ä¸åŒã€‚



**ç”Ÿæˆ**ã€‚
å¦‚ä¸Šæ‰€è¿°ï¼Œè¯­è¨€æ¨¡å‹$$p$$å¯¹ä¸€æ®µåºåˆ—è¿›è¡Œè¯„ä¼°ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ¦‚ç‡å€¼æ¥è¯„ä¼°å®ƒçš„å¥½åã€‚
æˆ‘ä»¬ä¹Ÿå¯ä»¥æ ¹æ®è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸€ä¸ªåºåˆ—ã€‚
æœ€çº¯ç²¹çš„æ–¹æ³•æ˜¯ä»è¯­è¨€æ¨¡å‹$$p$$ä¸­æŠ½æ ·ç”Ÿæˆä¸€ä¸ªåºåˆ—$$x_{1:L}$$ï¼Œå…¶æ¦‚ç‡ç­‰äº$$p(x_{1:L})$$ï¼Œè¡¨ç¤ºä¸ºï¼š

$$x_{1:L} \sim p.$$


å¦‚ä½•è¿›è¡Œé«˜æ•ˆçš„è®¡ç®—å–å†³äºè¯­è¨€æ¨¡å‹$$p$$çš„å½¢å¼ã€‚
åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¸ç›´æ¥ä»è¯­è¨€æ¨¡å‹ä¸­è¿›è¡ŒæŠ½æ ·ï¼Œ
è¿™æ—¢æ˜¯ç”±äºç°å®è¯­è¨€æ¨¡å‹çš„é™åˆ¶ï¼Œ
ä¹Ÿæ˜¯å› ä¸ºæˆ‘ä»¬æœ‰æ—¶å¸Œæœ›è·å¾—çš„ä¸æ˜¯â€œå¹³å‡â€åºåˆ—ï¼Œ
è€Œæ˜¯æ›´æ¥è¿‘äºâ€œæœ€ä¼˜â€åºåˆ—çš„ç”Ÿæˆç»“æœã€‚

### è‡ªå›å½’è¯­è¨€æ¨¡å‹


ä¸€ç§å¸¸ç”¨æ–¹æ³•æ˜¯ä½¿ç”¨**æ¦‚ç‡è¿ä¹˜æ³•åˆ™**æ¥è¡¨ç¤ºåºåˆ—$$x_{1:L}$$çš„è”åˆåˆ†å¸ƒ$$p(x_{1:L})$$:

$$p(x_{1:L}) = p(x_1) p(x_2 \mid x_1) p(x_3 \mid x_1, x_2) \cdots p(x_L \mid x_{1:L-1}) = \prod_{i=1}^L p(x_i \mid x_{1:i-1}).$$

ä¾‹å¦‚
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=the%20mouse%20ate%20the%20cheese&settings=echo_prompt%3A%20true%0Amax_tokens%3A%200%0Atop_k_per_token%3A%2010&environments=)):

$$
\begin{align*}
p(\nl{the}, \nl{mouse}, \nl{ate}, \nl{the}, \nl{cheese}) = \,
& p(\nl{the}) \\
& p(\nl{mouse} \mid \nl{the}) \\
& p(\nl{ate} \mid \nl{the}, \nl{mouse}) \\
& p(\nl{the} \mid \nl{the}, \nl{mouse}, \nl{ate}) \\
& p(\nl{cheese} \mid \nl{the}, \nl{mouse}, \nl{ate}, \nl{the}).
\end{align*}
$$

ç‰¹åˆ«åœ°ï¼Œ$$p(x_i \mid x_{1:i-1})$$æ˜¯ç»™å®šå‰é¢token $$x_{1:i-1}$$ä¹‹åï¼Œä¸‹ä¸€ä¸ªtoken $$x_i$$çš„**æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒ**ã€‚

å½“ç„¶ï¼Œä»»ä½•è”åˆæ¦‚ç‡åˆ†å¸ƒéƒ½å¯ä»¥ç”¨è¿™ç§æ•°å­¦æ–¹å¼æ¥è¡¨ç¤ºï¼Œ
ä½†**è‡ªå›å½’è¯­è¨€æ¨¡å‹**æ˜¯å…¶ä¸­æ¯ä¸ªæ¡ä»¶åˆ†å¸ƒ$$p(x_i \mid x_{1:i-1})$$éƒ½å¯ä»¥é«˜æ•ˆåœ°è®¡ç®—å‡ºæ¥çš„ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨å‰é¦ˆç¥ç»ç½‘ç»œï¼‰ã€‚

**ç”Ÿæˆ**ã€‚ ç°åœ¨ï¼Œè¦ä»è‡ªå›å½’è¯­è¨€æ¨¡å‹$$p$$ä¸­ç”Ÿæˆæ•´ä¸ªåºåˆ—$$x_{1:L}$$ï¼Œ
æˆ‘ä»¬éœ€è¦ä»¥å‰é¢å·²ç”Ÿæˆçš„tokenä¸ºæ¡ä»¶é€ä¸ªé‡‡æ ·ï¼Œç”Ÿæˆtokenï¼š

$$
\text{for } i = 1, \dots, L: \\
\hspace{1in} x_i \sim p(x_i \mid x_{1:i-1})^{1/T},
$$



å…¶ä¸­$$T\ge 0$$æ˜¯ä¸€ä¸ª**æ¸©åº¦**å‚æ•°ï¼Œç”¨äºæ§åˆ¶æˆ‘ä»¬å¸Œæœ›ä»è¯­è¨€æ¨¡å‹ä¸­è·å¾—å¤šå°‘éšæœºæ€§ï¼š


- å½“$$T=0$$æ—¶ï¼Œæ¯ä¸ªä½ç½®$$i$$éƒ½ä¼šä»¥ç¡®å®šæ€§çš„æ–¹å¼é€‰æ‹©æœ€æœ‰å¯èƒ½çš„token $$x_i$$
- å½“$$T=1$$æ—¶ï¼Œä»è¯­è¨€æ¨¡å‹ä¸­æ­£å¸¸åœ°è¿›è¡Œé‡‡æ ·
- å½“$$T=\infty$$æ—¶ï¼Œä»æ•´ä¸ªè¯æ±‡è¡¨$$\sV$$çš„å‡åŒ€åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·
  
ä½†æ˜¯ï¼Œä»…ä»…å°†æ¦‚ç‡æé«˜åˆ°$$1/T$$æ¬¡å¹‚å¯èƒ½å¯¼è‡´æ¦‚ç‡åˆ†å¸ƒä¸ç­‰äº1ã€‚
æˆ‘ä»¬å¯ä»¥é€šè¿‡é‡æ–°è§„èŒƒåŒ–åˆ†å¸ƒæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
æˆ‘ä»¬å°†å½’ä¸€åŒ–ç‰ˆæœ¬ç§°ä¸º$$p_T(x_i \mid x_{1:i-1}) \propto p(x_i \mid x_{1:i-1})^{1/T}$$çš„**é€€ç«**æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒã€‚ä¾‹å¦‚ï¼š

$$p(\nl{cheese}) = 0.4, \quad\quad\quad p(\nl{mouse}) = 0.6$$

$$p_{T=0.5}(\nl{cheese}) = 0.31, \quad\quad\quad p_{T=0.5}(\nl{mouse}) = 0.69$$

$$p_{T=0.2}(\nl{cheese}) = 0.12, \quad\quad\quad p_{T=0.2}(\nl{mouse}) = 0.88$$

$$p_{T=0}(\nl{cheese}) = 0, \quad\quad\quad p_{T=0}(\nl{mouse}) = 1$$


*æ³¨*ï¼šé€€ç«ä¸­çš„â€œé€€ç«â€æ˜¯æŒ‡å†¶é‡‘å­¦ä¸­ï¼Œçƒ­çš„ææ–™é€æ¸å†·å´ï¼Œè¿™ç§æ–¹æ³•å¸¸å¸¸åœ¨é‡‡æ ·å’Œä¼˜åŒ–ç®—æ³•ä¸­å‡ºç°ï¼Œæ¯”å¦‚æ¨¡æ‹Ÿé€€ç«ç®—æ³•ã€‚

*æŠ€æœ¯ç»†èŠ‚*ï¼šåˆ†åˆ«å¯¹æ¯ä¸ªæ¡ä»¶åˆ†å¸ƒ$$p(x_i \mid x_{1:i-1})^{1/T}$$é‡‡æ ·ä¸ç­‰ä»·äºä»é•¿åº¦ä¸º$$L$$çš„å·²é€€ç«åˆ†å¸ƒä¸­é‡‡æ ·ï¼ˆé™¤é$$T=1$$ï¼‰ã€‚

**æ¡ä»¶ç”Ÿæˆ**ã€‚
æ›´ä¸€èˆ¬åœ°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æŒ‡å®šä¸€äº›å‰ç¼€åºåˆ—$$x_{1:i}$$ï¼ˆç§°ä¸º**æç¤ºï¼Œprompt**ï¼‰å¹¶å¯¹å…¶ä½™çš„$$x_{i+1:L}$$ï¼ˆç§°ä¸º**è¡¥å…¨ï¼Œcompletion**ï¼‰è¿›è¡Œé‡‡æ ·æ¥è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚
ä¾‹å¦‚, å½“$$T=0$$æ—¶ç”Ÿæˆçš„ç»“æœå¦‚ä¸‹:

([demo](http://crfm-models.stanford.edu/static/index.html?prompt=the%20mouse%20ate&settings=temperature%3A%200%0Amax_tokens%3A%202%0Atop_k_per_token%3A%2010%0Anum_completions%3A%2010&environments=)):

$$\underbrace{\nl{the}, \nl{mouse}, \nl{ate}}_\text{prompt} \generate{T=0} \underbrace{\nl{the}, \nl{cheese}}_\text{completion}.$$

å¦‚æœå°†æ¸©åº¦æ”¹ä¸º$$T=1$$ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ›´å¤šçš„å˜åŒ–ï¼š
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=the%20mouse%20ate&settings=temperature%3A%201%0Amax_tokens%3A%202%0Atop_k_per_token%3A%2010%0Anum_completions%3A%2010&environments=)),
ä¾‹å¦‚, $$\nl{its house}$$ and $$\nl{my homework}$$.

åœ¨åé¢ï¼Œå¾ˆå¿«æˆ‘ä»¬å°†çœ‹åˆ°ï¼Œé€šè¿‡ç®€å•åœ°æ›´æ”¹æç¤ºï¼Œæ¡ä»¶ç”Ÿæˆä¸ºè¯­è¨€æ¨¡å‹è§£å†³å„ç§ä»»åŠ¡æ‰“å¼€äº†å¤§é—¨ã€‚

### æ€»ç»“

- è¯­è¨€æ¨¡å‹æ˜¯ä¸€ä¸ªå¯¹åºåˆ—$$x_{1:L}$$çš„æ¦‚ç‡åˆ†å¸ƒ$$p$$ã€‚
- ç›´è§‚åœ°ï¼Œä¸€ä¸ªå¥½çš„è¯­è¨€æ¨¡å‹åº”è¯¥å…·æœ‰è¯­è¨€èƒ½åŠ›å’Œä¸–ç•ŒçŸ¥è¯†ã€‚
- ç»™å®šæç¤º$$x_{1:i}$$ï¼Œè‡ªå›å½’è¯­è¨€æ¨¡å‹å¯ä»¥æœ‰æ•ˆçš„æ–¹å¼ç”Ÿæˆå®Œæˆ$$x_{i+1:L}$$ã€‚
- æ¸©åº¦å¯ä»¥ç”¨æ¥æ§åˆ¶ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å˜åŒ–ç¨‹åº¦ã€‚
  
## è¯­è¨€æ¨¡å‹ç®€å²

### ä¿¡æ¯è®ºï¼Œè‹±è¯­ç†µï¼Œn-gramæ¨¡å‹


**ä¿¡æ¯è®º**ã€‚è¯­è¨€æ¨¡å‹å¯ä»¥è¿½æº¯åˆ°å…‹åŠ³å¾·Â·é¦™å†œï¼ˆClaude Shannonï¼‰ï¼Œä»–åœ¨1948å¹´å‘è¡¨äº†å…·æœ‰å¼€åˆ›æ€§çš„è®ºæ–‡[ã€Šé€šä¿¡çš„æ•°å­¦ç†è®ºã€‹ï¼ˆA Mathematical Theory of Communicationï¼‰](https://dl.acm.org/doi/pdf/10.1145/584091.584093)ï¼Œåˆ›ç«‹äº†ä¿¡æ¯è®ºã€‚åœ¨è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œä»–å°†åˆ†å¸ƒçš„**ç†µ**ä½œä¸ºä¸€ç§åº¦é‡ä¿¡æ¯é‡çš„æ–¹æ³•å¼•å…¥ã€‚

$$H(p) = \sum_x p(x) \log \frac{1}{p(x)}.$$


ç†µï¼ˆEntropyï¼‰æ˜¯æŒ‡å¯¹äºæ¦‚ç‡åˆ†å¸ƒä¸­çš„ä¸€ä¸ªæ ·æœ¬$$x \sim p$$ï¼Œ**ä»»ä½•ç®—æ³•**éœ€è¦ç¼–ç ï¼ˆå‹ç¼©ï¼‰å®ƒä¸ºä¸€ä¸ªæ¯”ç‰¹ä¸²çš„å¹³å‡æ¯”ç‰¹æ•°:


$$\nl{the mouse ate the cheese} \Rightarrow 0001110101.$$

- ç†µè¶Šä½ï¼Œåºåˆ—çš„"ç»“æ„åŒ–"ç¨‹åº¦è¶Šé«˜ï¼Œä»£ç é•¿åº¦è¶ŠçŸ­ã€‚
- ç›´è§‚åœ°è¯´ï¼Œ$$\log \frac{1}{p(x)}$$ æ˜¯ç”¨äºè¡¨ç¤ºå‡ºç°æ¦‚ç‡ä¸º $$p(x)$$ çš„å…ƒç´  $$x$$ çš„ä»£ç é•¿åº¦ã€‚
- å¦‚æœ $$p(x) = \frac{1}{8}$$ï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥åˆ†é… $$\log_2(8) = 3$$ ä½ï¼ˆç­‰ä»·äº $$\log(8) = 2.08$$ natsï¼‰ã€‚
  
*æ—æ³¨*ï¼šå®é™…è¾¾åˆ°é¦™å†œæé™å¹¶ä¸ç®€å•ï¼ˆä¾‹å¦‚ï¼ŒLDPCä»£ç ï¼‰ï¼Œè¿™æ˜¯ç¼–ç ç†è®ºçš„è¯é¢˜ã€‚

**è‹±è¯­çš„ç†µ**ã€‚Shannonç‰¹åˆ«æ„Ÿå…´è¶£çš„æ˜¯æµ‹é‡è‹±è¯­ï¼ˆä»¥å­—æ¯åºåˆ—è¡¨ç¤ºï¼‰çš„ç†µã€‚è¿™æ„å‘³ç€æˆ‘ä»¬æƒ³è±¡å­˜åœ¨ä¸€ä¸ªâ€œçœŸå®â€çš„åˆ†å¸ƒ $$p$$ ï¼ˆå­˜åœ¨æ€§æ˜¯æœ‰é—®é¢˜çš„ï¼Œä½†å®ƒä»ç„¶æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„æ•°å­¦æŠ½è±¡ï¼‰ï¼Œå¯ä»¥äº§ç”Ÿè‹±è¯­æ–‡æœ¬æ ·æœ¬ $$x \sim p$$ ã€‚

Shannonä¹Ÿå®šä¹‰äº†**äº¤å‰ç†µ**ï¼š


$$H(p, q) = \sum_x p(x) \log \frac{1}{q(x)},$$

è¿™é‡Œä»‹ç»çš„æ˜¯é€šè¿‡æ¨¡å‹$q$ç»™å®šçš„å‹ç¼©æ–¹æ¡ˆå¯¹æ ·æœ¬$$x\sim p$$è¿›è¡Œç¼–ç æ‰€éœ€çš„é¢„æœŸæ¯”ç‰¹æ•°ï¼ˆnatsï¼‰ï¼Œå…¶ä¸­$q(x)$è¡¨ç¤ºç”¨é•¿åº¦ä¸º$$\frac{1}{q(x)}$$çš„ç¼–ç æ¥è¡¨ç¤º$$x$$ã€‚

**é€šè¿‡è¯­è¨€å»ºæ¨¡ä¼°è®¡ç†µ**
ä¸€ä¸ªé‡è¦çš„å±æ€§æ˜¯äº¤å‰ç†µ $$H(p, q)$$ é™åˆ¶äº†ç†µ $$H(p)$$çš„ä¸Šé™ã€‚

$$H(p, q) \ge H(p),$$

è¿™æ„å‘³ç€ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡æ„å»ºä¸€ä¸ªï¼ˆè¯­è¨€ï¼‰æ¨¡å‹ $$q$$ï¼Œå¹¶åªä½¿ç”¨æ¥è‡ªçœŸå®æ•°æ®åˆ†å¸ƒ $$p$$ çš„æ ·æœ¬æ¥ä¼°è®¡ $$H(p, q)$$ï¼Œè€Œå¦‚æœ $$p$$ æ˜¯è‹±æ–‡ï¼Œåˆ™é€šå¸¸æ— æ³•è·å¾— $$H(p)$$ã€‚

ä¸ºäº†æ›´å¥½åœ°ä¼°è®¡ç†µ$$H(p)$$ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºæ›´å¥½çš„æ¨¡å‹$$q$$ï¼Œå¹¶é€šè¿‡$$H(p, q)$$è¿›è¡Œæµ‹é‡ã€‚


**Shannonæ¸¸æˆï¼ˆäººç±»è¯­è¨€æ¨¡å‹ï¼‰**

1948å¹´ï¼ŒShannoné¦–æ¬¡å°†n-gramæ¨¡å‹ç”¨ä½œ$$q$$ï¼Œä½†åœ¨ä»–1951å¹´çš„è®ºæ–‡[Prediction and Entropy of Printed English](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6773263)ä¸­ï¼Œä»–å¼•å…¥äº†ä¸€ä¸ªå·§å¦™çš„æ–¹æ¡ˆï¼ˆç§°ä¸ºShannonæ¸¸æˆï¼‰ï¼Œå…¶ä¸­$$q$$ç”±äººç±»æä¾›ï¼š

$$\nl{the mouse ate my ho_}$$

äººç±»ä¸æ“…é•¿æä¾›ä»»æ„æ–‡æœ¬çš„æ ¡å‡†æ¦‚ç‡ï¼Œå› æ­¤åœ¨é¦™å†œæ¸¸æˆä¸­ï¼Œäººç±»è¯­è¨€æ¨¡å‹ä¼šåå¤å°è¯•çŒœæµ‹ä¸‹ä¸€ä¸ªå­—æ¯ï¼Œå¹¶è®°å½•çŒœæµ‹æ¬¡æ•°ã€‚


### ç”¨äºä¸‹æ¸¸åº”ç”¨çš„N-gramæ¨¡å‹

è¯­è¨€æ¨¡å‹æœ€æ—©è¢«ç”¨äºéœ€è¦ç”Ÿæˆæ–‡æœ¬çš„å®é™…åº”ç”¨åœºæ™¯ï¼š
- 20ä¸–çºª70å¹´ä»£çš„è¯­éŸ³è¯†åˆ«ï¼ˆè¾“å…¥ï¼šå£°å­¦ä¿¡å·ï¼Œè¾“å‡ºï¼šæ–‡æœ¬ï¼‰ï¼Œ
- 20ä¸–çºª90å¹´ä»£çš„æœºå™¨ç¿»è¯‘ï¼ˆè¾“å…¥ï¼šæºè¯­è¨€æ–‡æœ¬ï¼Œè¾“å‡ºï¼šç›®æ ‡è¯­è¨€æ–‡æœ¬ï¼‰ã€‚

**å™ªå£°ä¿¡é“æ¨¡å‹**ã€‚
è§£å†³è¿™äº›ä»»åŠ¡çš„ä¸»è¦èŒƒå¼æ˜¯**å™ªå£°ä¿¡é“æ¨¡å‹**ã€‚
ä»¥è¯­éŸ³è¯†åˆ«ä¸ºä¾‹ï¼š
- æˆ‘ä»¬å‡è®¾å­˜åœ¨ä¸€äº›ä»åˆ†å¸ƒ$$p$$ä¸­æŠ½å–çš„æ–‡æœ¬ã€‚
- è¿™äº›æ–‡æœ¬è¢«å®ç°ä¸ºè¯­éŸ³ï¼ˆå£°å­¦ä¿¡å·ï¼‰ã€‚
- ç„¶åï¼Œé‰´äºè¯­éŸ³ï¼Œæˆ‘ä»¬å¸Œæœ›æ¢å¤ï¼ˆæœ€æœ‰å¯èƒ½çš„ï¼‰æ–‡æœ¬ã€‚
  
è¿™å¯ä»¥é€šè¿‡è´å¶æ–¯å®šç†å®Œæˆï¼š

$$p(\text{text} \mid \text{speech}) \propto \underbrace{p(\text{text})}_\text{language model} \underbrace{p(\text{speech} \mid \text{text})}_\text{acoustic model}.$$

è¯­éŸ³è¯†åˆ«å’Œæœºå™¨ç¿»è¯‘ç³»ç»Ÿä½¿ç”¨n-gramè¯­è¨€æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹ä½œç”¨äºå•è¯ä¸Šï¼ˆæœ€åˆç”±Shannonå¼•å…¥ï¼Œä½†æ˜¯é’ˆå¯¹çš„æ˜¯å­—ç¬¦ï¼‰ã€‚

**N-gram æ¨¡å‹**ã€‚
åœ¨**N-gramæ¨¡å‹**ä¸­ï¼Œ
å¯¹äºä¸€ä¸ªtoken $$x_i$$ çš„é¢„æµ‹ï¼Œåªä¾èµ–äºæœ€åçš„$$n-1$$ä¸ªå­—ç¬¦$$x_{i-(n-1):i-1}$$ï¼Œè€Œä¸æ˜¯æ•´ä¸ªå†å²è®°å½•ï¼š

$$p(x_i \mid x_{1:i-1}) = p(x_i \mid x_{i-(n-1):i-1}).$$

ä¾‹å¦‚ï¼Œä¸€ä¸ªä¸‰å…ƒæ¨¡å‹ï¼ˆ$$n=3$$ï¼‰ä¼šå®šä¹‰ï¼š

$$p(\nl{cheese} \mid \nl{the}, \nl{mouse}, \nl{ate}, \nl{the}) = p(\nl{cheese} \mid \nl{ate}, \nl{the}).$$

è¿™äº›æ¦‚ç‡æ˜¯åŸºäºåœ¨å¤§é‡æ–‡æœ¬è¯­æ–™åº“ä¸­å‡ºç°å„ç§ n-gramsï¼ˆä¾‹å¦‚ï¼Œ$$\nl{ate the mouse}$$ å’Œ $$\nl{ate the cheese}$$ï¼‰çš„æ¬¡æ•°è®¡ç®—çš„ï¼Œå¹¶é€‚å½“åœ°å¹³æ»‘ä»¥é¿å…è¿‡æ‹Ÿåˆï¼ˆä¾‹å¦‚ï¼ŒKneser-Neyå¹³æ»‘ï¼‰ã€‚



å°†æ•°æ®æ‹Ÿåˆåˆ°n-gramæ¨¡å‹éå¸¸**è®¡ç®—å»‰ä»·**ä¸”å¯æ‰©å±•ã€‚å› æ­¤ï¼Œn-gramæ¨¡å‹è¢«è®­ç»ƒç”¨äºæµ·é‡æ–‡æœ¬ã€‚ä¾‹å¦‚ï¼Œ[Brantsç­‰äººï¼ˆ2007ï¼‰](https://aclanthology.org/D07-1090.pdf) å¯¹2ä¸‡äº¿tokenè¿›è¡Œäº†5å…ƒæ¨¡å‹çš„æœºå™¨ç¿»è¯‘è®­ç»ƒã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒGPT-3ä»…ç»è¿‡äº†3000äº¿tokençš„è®­ç»ƒã€‚ç„¶è€Œï¼Œn-gramæ¨¡å‹åœ¨æœ¬è´¨ä¸Šå­˜åœ¨å±€é™æ€§ã€‚æƒ³è±¡ä¸€ä¸‹å‰ç¼€ï¼š


$$\nl{Stanford has a new course on large language models.  It will be taught by ___}$$


å¦‚æœ$$n$$å¤ªå°ï¼Œæ¨¡å‹å°†æ— æ³•æ•æ‰åˆ°é•¿ç¨‹ä¾èµ–å…³ç³»ï¼Œä¸‹ä¸€ä¸ªå•è¯å°†æ— æ³•ä¾èµ–äº$$\nl{Stanford}$$ã€‚ç„¶è€Œï¼Œå¦‚æœ$$n$$å¤ªå¤§ï¼Œè·å¾—æ¦‚ç‡çš„è‰¯å¥½ä¼°è®¡å°†æ˜¯**ç»Ÿè®¡ä¸Šä¸å¯è¡Œ**ï¼ˆå³ä½¿åœ¨â€œå·¨å¤§â€çš„è¯­æ–™åº“ä¸­ï¼Œå‡ ä¹æ‰€æœ‰åˆç†çš„é•¿åºåˆ—éƒ½ä¸ä¼šå‡ºç°ï¼‰ï¼š


$$\text{count}(\nl{Stanford}, \nl{has}, \nl{a}, \nl{new}, \nl{course}, \nl{on}, \nl{large}, \nl{language}, \nl{models}) = 0.$$

å› æ­¤ï¼Œè¯­è¨€æ¨¡å‹åªé™äºè¯¸å¦‚è¯­éŸ³è¯†åˆ«å’Œæœºå™¨ç¿»è¯‘ç­‰ä»»åŠ¡ï¼Œå…¶ä¸­å£°å­¦ä¿¡å·æˆ–æºæ–‡æœ¬æä¾›äº†è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œä»¥è‡³äºä»…æ•è·**æœ¬åœ°ä¾èµ–æ€§**ï¼ˆè€Œæ— æ³•æ•è·é•¿è·ç¦»ä¾èµ–æ€§ï¼‰å¹¶ä¸æ˜¯ä¸€ä¸ªå·¨å¤§çš„é—®é¢˜ã€‚


### ç¥ç»è¯­è¨€æ¨¡å‹

å¯¹äºè¯­è¨€æ¨¡å‹æ¥è¯´ï¼Œé‡è¦çš„è¿›æ­¥æ˜¯å¼•å…¥ç¥ç»ç½‘ç»œã€‚
[Bengio et al., 2003](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) æå‡ºäº†ç¥ç»è¯­è¨€æ¨¡å‹ï¼Œ


å…¶ä¸­$$p(x_i \mid x_{i-(n-1):i-1})$$ ç”±ç¥ç»ç½‘ç»œç»™å‡ºï¼š


$$p(\nl{cheese} \mid \nl{ate}, \nl{the}) = \text{some-neural-network}(\nl{ate}, \nl{the}, \nl{cheese}).$$

è¯·æ³¨æ„ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ä»ç„¶å—$$n$$çš„é™åˆ¶ï¼Œä½†ç°åœ¨ä¼°è®¡ç¥ç»è¯­è¨€æ¨¡å‹å¯¹äºæ›´å¤§çš„$$n$$å€¼æ˜¯**ç»Ÿè®¡ä¸Šå¯è¡Œ**çš„ã€‚

ç°åœ¨ï¼Œä¸»è¦çš„æŒ‘æˆ˜æ˜¯è®­ç»ƒç¥ç»ç½‘ç»œéœ€è¦æ›´é«˜çš„**è®¡ç®—èµ„æº**ã€‚ä»–ä»¬ä»…ä»…ä½¿ç”¨äº†1400ä¸‡ä¸ªå•è¯æ¥è®­ç»ƒæ¨¡å‹ï¼Œå¹¶ä¸”è¡¨æ˜è¯¥æ¨¡å‹æ¯”åŒæ ·æ•°é‡çš„æ•°æ®è®­ç»ƒå‡ºæ¥çš„n-gramæ¨¡å‹è¡¨ç°æ›´å¥½ã€‚ä½†ç”±äºn-gramæ¨¡å‹æ›´å…·å¯æ‰©å±•æ€§ï¼Œè€Œæ•°æ®ä¸æ˜¯ç“¶é¢ˆï¼Œn-gramæ¨¡å‹åœ¨è‡³å°‘æ¥ä¸‹æ¥çš„åå¹´ä¸­ä»ç„¶å æ®ä¸»å¯¼åœ°ä½ã€‚

è‡ª2003å¹´ä»¥æ¥ï¼Œç¥ç»è¯­è¨€å»ºæ¨¡çš„å¦å¤–ä¸¤ä¸ªå…³é”®å‘å±•åŒ…æ‹¬ï¼š 

- **å¾ªç¯ç¥ç»ç½‘ç»œ**ï¼ˆRNNï¼‰ï¼ŒåŒ…æ‹¬é•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰ï¼Œå…è®¸ä¸€ä¸ªtoken $$x_i$$ çš„æ¡ä»¶åˆ†å¸ƒå–å†³äº**æ•´ä¸ªä¸Šä¸‹æ–‡** $$x_{1:i-1}$$ï¼ˆç­‰æ•ˆåœ°å– $$n = \infty$$ï¼‰ï¼Œä½†æ˜¯è¿™äº›å¾ˆéš¾è®­ç»ƒã€‚
- **Transformers** æ˜¯ä¸€ç§è¾ƒæ–°çš„æ¶æ„ï¼ˆäº2017å¹´å¼€å‘å‡ºæ¥ç”¨äºæœºå™¨ç¿»è¯‘ï¼‰ï¼Œå†æ¬¡å°†ä¸Šä¸‹æ–‡é•¿åº¦å›ºå®šä¸º $$n$$ï¼Œä½†è®­ç»ƒèµ·æ¥å´æ›´åŠ  **å®¹æ˜“**ï¼ˆå¹¶åˆ©ç”¨äº†GPUçš„å¹¶è¡Œæ€§ï¼‰ã€‚æ­¤å¤–ï¼Œ$$n$$å¯ä»¥è¢«è®¾ç½®ä¸º "è¶³å¤Ÿå¤§" ä»¥é€‚åº”è®¸å¤šåº”ç”¨ï¼ˆå¦‚GPT-3ä½¿ç”¨ $$n=2048$$ï¼‰ã€‚

æˆ‘ä»¬ä¼šåœ¨è¯¾ç¨‹çš„åé¢è¯¦ç»†åˆ†æå¹¶æ›´æ·±å…¥åœ°äº†è§£æ¶æ„å’Œè®­ç»ƒã€‚

### æ€»ç»“

- è¯­è¨€æ¨¡å‹æœ€åˆåœ¨ä¿¡æ¯ç†è®ºçš„èƒŒæ™¯ä¸‹è¢«ç ”ç©¶ï¼Œå¹¶å¯ç”¨äºä¼°è®¡è‹±è¯­çš„ç†µã€‚
- N-gramæ¨¡å‹è®¡ç®—æ•ˆç‡éå¸¸é«˜ï¼Œä½†ç»Ÿè®¡æ•ˆç‡ä½ã€‚
- N-gramæ¨¡å‹å¯¹äºçŸ­ä¸Šä¸‹æ–‡åœºæ™¯ä¸å¦ä¸€äº›æ¨¡å‹ï¼ˆç”¨äºè¯­éŸ³è¯†åˆ«çš„å£°å­¦æ¨¡å‹æˆ–ç”¨äºæœºå™¨ç¿»è¯‘çš„ç¿»è¯‘æ¨¡å‹ï¼‰ç»“åˆä½¿ç”¨éå¸¸æœ‰æ•ˆã€‚
- ç¥ç»è¯­è¨€æ¨¡å‹å…·æœ‰ç»Ÿè®¡æ•ˆç‡é«˜ä½†è®¡ç®—æ•ˆç‡ä½çš„ç‰¹ç‚¹ã€‚
- éšç€æ—¶é—´çš„æ¨ç§»ï¼Œè®­ç»ƒå¤§å‹ç¥ç»ç½‘ç»œå·²ç»å˜å¾—è¶³å¤Ÿå¯è¡Œï¼Œç¥ç»è¯­è¨€æ¨¡å‹å·²ç»æˆä¸ºä¸»å¯¼èŒƒå¼ã€‚

## ä¸ºä»€ä¹ˆä¼šæœ‰è¿™é—¨è¯¾ç¨‹ï¼Ÿ

ä»‹ç»äº†è¯­è¨€æ¨¡å‹ä¹‹åï¼Œäººä»¬å¯èƒ½ä¼šæƒ³çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¸“é—¨é’ˆå¯¹ **å¤§å‹** è¯­è¨€æ¨¡å‹çš„è¯¾ç¨‹ã€‚


**å°ºå¯¸å¢åŠ **ã€‚
é¦–å…ˆï¼Œæˆ‘ä»¬æ‰€è¯´çš„â€œå¤§â€æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿéšç€æ·±åº¦å­¦ä¹ åœ¨2010å¹´ä»£çš„å…´èµ·ä»¥åŠä¸»è¦ç¡¬ä»¶çš„è¿›æ­¥ï¼ˆä¾‹å¦‚GPUï¼‰ï¼Œç¥ç»è¯­è¨€æ¨¡å‹çš„å¤§å°å·²ç»é£™å‡ã€‚ä»¥ä¸‹è¡¨æ ¼æ˜¾ç¤ºï¼Œä»…åœ¨è¿‡å»çš„4å¹´ä¸­ï¼Œæ¨¡å‹å¤§å°å·²ç»å¢åŠ äº†**5000å€**ï¼š 


| Model               | Organization      | Date     | Size (# params) |
|---------------------|-------------------|----------|----------------:|
| ELMo                | AI2               | Feb 2018 | 94,000,000      |
| GPT                 | OpenAI            | Jun 2018 | 110,000,000     |
| BERT                | Google            | Oct 2018 | 340,000,000     |
| XLM                 | Facebook          | Jan 2019 | 655,000,000     |
| GPT-2               | OpenAI            | Mar 2019 | 1,500,000,000   |
| RoBERTa             | Facebook          | Jul 2019 | 355,000,000     |
| Megatron-LM         | NVIDIA            | Sep 2019 | 8,300,000,000   |
| T5                  | Google            | Oct 2019 | 11,000,000,000  |
| Turing-NLG          | Microsoft         | Feb 2020 | 17,000,000,000  |
| GPT-3               | OpenAI            | May 2020 | 175,000,000,000 |
| Megatron-Turing NLG | Microsoft, NVIDIA | Oct 2021 | 530,000,000,000 |
| Gopher              | DeepMind          | Dec 2021 | 280,000,000,000 |

**æ¶Œç°**ã€‚
è§„æ¨¡çš„å·®å¼‚æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ
å°½ç®¡å¤§å¤šæ•°æŠ€æœ¯æœºå™¨éƒ½æ˜¯ç›¸åŒçš„ï¼Œä½†ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œâ€œåªæ˜¯æ‰©å¤§è§„æ¨¡â€è¿™äº›æ¨¡å‹ä¼šäº§ç”Ÿæ–°çš„**æ¶Œç°è¡Œä¸º**ï¼Œä»è€Œå¯¼è‡´å…·æœ‰è´¨çš„ä¸åŒçš„èƒ½åŠ›å’Œè´¨çš„ä¸åŒ
ç¤¾ä¼šå½±å“ã€‚

*æ—æ³¨*ï¼šåœ¨æŠ€æœ¯å±‚é¢ä¸Šï¼Œæˆ‘ä»¬ä¸“æ³¨äºè‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼Œä½†è®¸å¤šæƒ³æ³•ä¹Ÿé€‚ç”¨äºæ©ç è¯­è¨€æ¨¡å‹ï¼Œå¦‚BERTå’ŒRoBERTaã€‚


### å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›

è™½ç„¶ç›´åˆ°2018å¹´ä¸ºæ­¢ï¼Œè¯­è¨€æ¨¡å‹ä¸»è¦è¢«ç”¨ä½œæ›´å¤§ç³»ç»Ÿçš„ä¸€ä¸ªç»„æˆéƒ¨åˆ†ï¼ˆä¾‹å¦‚è¯­éŸ³è¯†åˆ«æˆ–æœºå™¨ç¿»è¯‘ï¼‰ï¼Œä½†æ˜¯è¯­è¨€æ¨¡å‹è¶Šæ¥è¶Šæœ‰èƒ½åŠ›æˆä¸ºä¸€ä¸ªç‹¬ç«‹çš„ç³»ç»Ÿï¼Œè¿™åœ¨ä»¥å‰æ˜¯ä¸å¯æƒ³è±¡çš„ã€‚

å›æƒ³ä¸€ä¸‹ï¼Œè¯­è¨€æ¨¡å‹å¯ä»¥è¿›è¡Œ**æ¡ä»¶ç”Ÿæˆ**ï¼šç»™å®šä¸€ä¸ªæç¤ºï¼Œç”Ÿæˆä¸€æ®µå®Œæˆçš„æ–‡æœ¬ï¼š

$$\text{prompt} \generate{} \text{completion}.$$

**èƒ½åŠ›ç¤ºä¾‹**ã€‚
è¿™ä¸ªç®€å•çš„ç•Œé¢å¯ä»¥é€šè¿‡æ›´æ”¹æç¤ºæ¥ä½¿è¯­è¨€æ¨¡å‹è§£å†³å„ç§å„æ ·çš„ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥é€šè¿‡å¡«ç©ºçš„æ–¹å¼æ¥è¿›è¡Œ**é—®ç­”**
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=Frederic%20Chopin%20was%20born%20in&settings=temperature%3A%200%0Astop_sequences%3A%20%5B.%5D%0Atop_k_per_token%3A%205&environments=)):

$$\nl{Frederic}, \nl{Chopin}, \nl{was}, \nl{born}, \nl{in} \generate{T=0} \nl{1810}, \nl{in}, \nl{Poland}$$

å¯ä»¥é€šè¿‡æç¤ºè¯­è¨€æ¨¡å‹æ¥è§£å†³**è¯æ±‡ç±»æ¯”**é—®é¢˜
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=sky%20%3A%20blue%20%3A%3A%20grass%20%3A&settings=temperature%3A%200%20%20%23%20Deterministic%0Amax_tokens%3A%201%0Atop_k_per_token%3A%205&environments=)):

$$\nl{sky}, \nl{:}, \nl{blue}, \nl{::}, \nl{grass}, \nl{:} \generate{T=0} \nl{green}$$

äººä»¬å¯ä»¥ä¿ƒä½¿è¯­è¨€æ¨¡å‹åŸºäºä¸€ä¸ªæ ‡é¢˜**ç”Ÿæˆä¸€ç¯‡æ–°é—»æ–‡ç« **
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=Title%3A%20New%20Course%20on%20Understanding%20and%20Developing%20Large%20Language%20Models%20(CS324)%0AArticle%3A%20On%20January%203%2C&settings=temperature%3A%200.5%0Amax_tokens%3A%20200%0Atop_k_per_token%3A%205&environments=)).
ä»¥ä¸‹æ˜¯GPT-3ç”Ÿæˆçš„ä¸€ç¯‡æ–‡ç« ç¤ºä¾‹ï¼ˆåŠ ç²—æ–‡æœ¬åï¼‰ï¼š


> **Title: NLP Researchers at Stanford Discover Black Holes in Language Models<br>
> Article: On January 3,** 2007, the Stanford University News Service published
> an article that reported a remarkable discovery by NLP researchers at
> Stanford. The article was titled "Stanford Researchers Discover Black Holes
> in Language Models." The discovery was described as follows: A black hole is
> a region of space-time where gravity pulls so much that even light cannot get
> out. Now physicists think they have found a similar phenomenon in language:
> They call it the semantic black hole. It occurs when a word or phrase has no
> clear definition â€“ and sometimes no clear meaning at all. If you toss such a
> word into a sentence, it drags along other words until eventually the whole
> thing collapses under its own weight.  "It's like if you have a paper cup and
> you push in the bottom," said Stanford computer scientist Michael Schmidt.
> "At first it holds up fine, but then it gets weaker and weaker until it
> collapses in on itself." Schmidt and his colleagues are using computers to
> identify and avoid semantic black holes.

**ä¸Šä¸‹æ–‡å­¦ä¹ **ã€‚
GPT-3æœ€å¼•äººå…¥èƒœçš„ä¸€ç‚¹å¯èƒ½æ˜¯å®ƒå¯ä»¥æ‰§è¡Œæ‰€è°“çš„**ä¸Šä¸‹æ–‡å­¦ä¹ **ã€‚
è®©æˆ‘ä»¬ä»ä¸€ä¸ªç¤ºä¾‹å¼€å§‹
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=Input%3A%20Where%20is%20Stanford%20University%3F%0AOutput%3A&settings=temperature%3A%200%0Astop_sequences%3A%20%5B%5Cn%5D%0Atop_k_per_token%3A%205&environments=)):

> **Input: Where is Stanford University?<br>
> Output:** Stanford University is in California.

æˆ‘ä»¬ï¼ˆiï¼‰çœ‹åˆ°GPT-3ç»™å‡ºçš„ç­”æ¡ˆä¸æ˜¯æœ€å…·ä¿¡æ¯é‡çš„ï¼Œï¼ˆiiï¼‰ä¹Ÿè®¸æ›´æƒ³ç›´æ¥å¾—åˆ°ç­”æ¡ˆè€Œä¸æ˜¯å®Œæ•´çš„å¥å­ã€‚


ç±»ä¼¼äºä¹‹å‰çš„è¯æ±‡ç±»æ¯”ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºä¸€ä¸ªæç¤ºï¼Œå…¶ä¸­åŒ…æ‹¬è¾“å…¥/è¾“å‡ºçš„**ç¤ºä¾‹**ã€‚ GPT-3é€šè¿‡è¿™äº›ç¤ºä¾‹æ›´å¥½åœ°ç†è§£ä»»åŠ¡ï¼Œå¹¶èƒ½å¤Ÿç”Ÿæˆæ‰€éœ€çš„ç­”æ¡ˆï¼ˆæ¼”ç¤ºï¼‰ã€‚
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=Input%3A%20Where%20is%20MIT%3F%0AOutput%3A%20Cambridge%0A%0AInput%3A%20Where%20is%20University%20of%20Washington%3F%0AOutput%3A%20Seattle%0A%0AInput%3A%20Where%20is%20Stanford%20University%3F%0AOutput%3A&settings=temperature%3A%200%0Astop_sequences%3A%20%5B%5Cn%5D%0Atop_k_per_token%3A%205&environments=)):

> **Input: Where is MIT?<br>
> Output: Cambridge<br>
> <br>
> Input: Where is University of Washington?<br>
> Output: Seattle<br>
> <br>
> Input: Where is Stanford University?<br>
> Output:** Stanford

**ä¸ç›‘ç£å­¦ä¹ çš„å…³ç³»**ã€‚
åœ¨å¸¸è§„çš„ç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬ä¼šæŒ‡å®šä¸€ç»„è¾“å…¥è¾“å‡ºå¯¹çš„æ•°æ®é›†ï¼Œå¹¶é€šè¿‡è®­ç»ƒæ¨¡å‹ï¼ˆä¾‹å¦‚é€šè¿‡æ¢¯åº¦ä¸‹é™è®­ç»ƒçš„ç¥ç»ç½‘ç»œï¼‰æ¥é€‚é…è¿™äº›ä¾‹å­ã€‚æ¯æ¬¡è®­ç»ƒéƒ½ä¼šäº§ç”Ÿä¸€ä¸ªä¸åŒçš„æ¨¡å‹ã€‚
ç„¶è€Œï¼Œåœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­ï¼Œåªæœ‰**ä¸€ä¸ªè¯­è¨€æ¨¡å‹**ï¼Œå¯ä»¥é€šè¿‡æç¤ºæ¥æ‰§è¡Œå„ç§ä¸åŒçš„ä»»åŠ¡ã€‚ä¸Šä¸‹æ–‡å­¦ä¹ è¶…å‡ºäº†ç ”ç©¶äººå‘˜é¢„æœŸçš„å¯èƒ½æ€§ï¼Œå¹¶ä¸”æ˜¯**æ¶Œç°**çš„ä¸€ä¸ªä¾‹å­ã€‚

*æ—æ³¨*: ç¥ç»è¯­è¨€æ¨¡å‹è¿˜å¯ä»¥äº§ç”Ÿå¥å­çš„å‘é‡è¡¨ç¤ºï¼Œè¿™äº›å‘é‡è¡¨ç¤ºå¯ä»¥ç”¨ä½œä¸‹æ¸¸ä»»åŠ¡çš„ç‰¹å¾ï¼Œæˆ–è€…ç›´æ¥è¿›è¡Œå¾®è°ƒä»¥ä¼˜åŒ–æ€§èƒ½ã€‚æˆ‘ä»¬ä¸“æ³¨äºé€šè¿‡æ¡ä»¶ç”Ÿæˆä½¿ç”¨è¯­è¨€æ¨¡å‹ï¼Œè¿™åªéœ€è¦ç®€å•çš„é»‘ç›’è®¿é—®ã€‚


### ç°å®ä¸–ç•Œä¸­çš„è¯­è¨€æ¨¡å‹

é‰´äºè¯­è¨€æ¨¡å‹çš„å¼ºå¤§èƒ½åŠ›ï¼Œå®ƒä»¬è¢«å¹¿æ³›é‡‡ç”¨å¹¶ä¸ä»¤äººæ„å¤–ã€‚

**ç ”ç©¶**ã€‚
é¦–å…ˆï¼Œåœ¨**ç ”ç©¶**é¢†åŸŸï¼Œå¤§å‹è¯­è¨€æ¨¡å‹å·²ç»å®Œå…¨æ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†ç¤¾åŒºã€‚å®é™…ä¸Šï¼Œå‡ ä¹æ‰€æœ‰æœ€å…ˆè¿›çš„ç³»ç»Ÿï¼Œæ¶µç›–æƒ…æ„Ÿåˆ†ç±»ã€é—®é¢˜å›ç­”ã€æ‘˜è¦å’Œæœºå™¨ç¿»è¯‘ç­‰å¹¿æ³›ä»»åŠ¡ï¼Œéƒ½åŸºäºæŸç§ç±»å‹çš„è¯­è¨€æ¨¡å‹ã€‚

**è¡Œä¸š**ã€‚
åœ¨å½±å“çœŸå®ç”¨æˆ·çš„**ç”Ÿäº§**ç³»ç»Ÿä¸­ï¼Œè¦ç¡®å®šå…¶ä¸­çš„æƒ…å†µæ›´åŠ å›°éš¾ï¼Œå› ä¸ºå¤§å¤šæ•°è¿™æ ·çš„ç³»ç»Ÿéƒ½æ˜¯å°é—­çš„ã€‚
ä»¥ä¸‹æ˜¯ä¸€äº›æ­£åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨çš„çŸ¥åå¤§å‹è¯­è¨€æ¨¡å‹çš„éå®Œæ•´åˆ—è¡¨ï¼š
- [Google Search](https://blog.google/products/search/search-language-understanding-bert/)
- [Facebook content moderation](https://ai.facebook.com/blog/harmful-content-can-evolve-quickly-our-new-ai-system-adapts-to-tackle-it/)
- [Microsoft's Azure OpenAI Service](https://blogs.microsoft.com/ai/new-azure-openai-service/)
- [AI21 Labs' writing assistance](https://www.ai21.com/)


è€ƒè™‘åˆ°åƒBERTè¿™æ ·çš„æ€§èƒ½æå‡ï¼Œä¼¼ä¹æ¯ä¸ªä½¿ç”¨è¯­è¨€çš„åˆ›ä¸šå…¬å¸éƒ½åœ¨æŸç§ç¨‹åº¦ä¸Šä½¿ç”¨è¿™äº›æ¨¡å‹ã€‚ç»¼åˆèµ·æ¥ï¼Œè¿™äº›æ¨¡å‹å› æ­¤**å½±å“ç€æ•°åäº¿äºº**ã€‚

ä¸€ä¸ªé‡è¦çš„è­¦å‘Šæ˜¯ï¼Œè¯­è¨€æ¨¡å‹ï¼ˆæˆ–ä»»ä½•æŠ€æœ¯ï¼‰åœ¨å·¥ä¸šä¸­çš„ä½¿ç”¨æ˜¯**å¤æ‚**çš„ã€‚å®ƒä»¬å¯èƒ½ä¼šè¢«å¾®è°ƒåˆ°ç‰¹å®šçš„åœºæ™¯ï¼Œå¹¶è¢«ç®€åŒ–ä¸ºæ›´å…·è®¡ç®—æ•ˆç‡çš„è¾ƒå°æ¨¡å‹ï¼Œä»¥ä¾¿åœ¨å¤§è§„æ¨¡æœåŠ¡ä¸­ä½¿ç”¨ã€‚å¯èƒ½ä¼šæœ‰å¤šä¸ªç³»ç»Ÿï¼ˆç”šè‡³å…¨éƒ¨åŸºäºè¯­è¨€æ¨¡å‹ï¼‰ï¼Œä»¥ååŒçš„æ–¹å¼ç”Ÿæˆç­”æ¡ˆã€‚


### é£é™©


åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»çœ‹åˆ°éšç€è¯­è¨€æ¨¡å‹çš„æ‰©å¤§ï¼Œå®ƒä»¬å˜å¾—èƒ½å¤Ÿè§£å†³è®¸å¤šä»»åŠ¡ã€‚ç„¶è€Œï¼Œå¹¶ä¸æ˜¯ä¸€åˆ‡éƒ½å¦‚æ­¤ç¾å¥½ï¼Œä½¿ç”¨è¯­è¨€æ¨¡å‹å­˜åœ¨**é‡å¤§é£é™©**ã€‚å¤šç¯‡è®ºæ–‡ï¼ŒåŒ…æ‹¬
[the stochastic parrots paper](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922),
[the foundation models report](https://arxiv.org/pdf/2108.07258.pdf), and
[DeepMind's paper on ethical and social harms](https://arxiv.org/pdf/2112.04359.pdf)
éƒ½è¯¦ç»†é˜è¿°äº†è¿™äº›é£é™©ã€‚è®©æˆ‘ä»¬å¼ºè°ƒå…¶ä¸­çš„ä¸€äº›ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬è¯¾ç¨‹ä¸­è¯¦ç»†ç ”ç©¶å®ƒä»¬ã€‚

**å¯é æ€§**ã€‚å¦‚æœæ‚¨å°è¯•ä½¿ç”¨GPT-3ï¼Œå®ƒçš„è¡¨ç°ä¼šæ¯”æ‚¨é¢„æœŸçš„è¦å¥½ï¼Œä½†å¤§éƒ¨åˆ†æ—¶é—´ï¼Œå®ƒä»ç„¶æ— æ³•äº§ç”Ÿæ­£ç¡®çš„ç­”æ¡ˆã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œç­”æ¡ˆå¯èƒ½*çœ‹èµ·æ¥*æ˜¯æ­£ç¡®çš„ï¼Œä½†å´æ²¡æœ‰åŠæ³•çŸ¥é“
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=Input%3A%20Who%20invented%20the%20Internet%3F%0AOutput%3A&settings=temperature%3A%200%0Astop_sequences%3A%20%5B%5Cn%5D%0Atop_k_per_token%3A%205&environments=))

> **Input: Who invented the Internet?<br>
> Output:** Al Gore

åœ¨é«˜é£é™©çš„åº”ç”¨ç¨‹åºä¸­ï¼Œä¾‹å¦‚åŒ»ç–—ä¿å¥é¢†åŸŸï¼Œæä¾›é”™è¯¯çš„ä¿¡æ¯æ˜¯ä¸å¯æ¥å—çš„ã€‚æˆ‘ä»¬å¦‚ä½•ä½¿è¯­è¨€æ¨¡å‹æ›´åŠ å¯é ï¼Ÿ

**ç¤¾ä¼šåè§**ã€‚å·²ç»æœ‰å¤§é‡è¯æ®è¡¨æ˜ï¼Œæœºå™¨å­¦ä¹ ç³»ç»Ÿå­˜åœ¨åè§ï¼šå®ƒä»¬åœ¨ä¸åŒäººç¾¤ä¸­è¡¨ç°å‡ºä¸åŒçš„æ€§èƒ½å·®è·ï¼Œå¹¶ä¸”å®ƒä»¬çš„é¢„æµ‹å¯èƒ½å¼ºåŒ–åˆ»æ¿å°è±¡ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è§‚å¯Ÿä»…ç”±ä¸€ä¸ªä»£è¯åŒºåˆ«çš„ä¸€å¯¹å¥å­çš„æ¦‚ç‡æ¥æ¢æµ‹è¯­è¨€æ¨¡å‹ä¸­å›ºæœ‰çš„åè§ã€‚
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=The%20software%20developer%20finished%20the%20program.%20%20%24%7Bpronoun%7D%20celebrated.&settings=echo_prompt%3A%20true%0Amax_tokens%3A%200&environments=pronoun%3A%20%5BHe%2C%20She%5D)):

> The software developer finished the program.  **He** celebrated.<br>
> The software developer finished the program.  **She** celebrated.


ç¤¾ä¼šåè§å½“ç„¶æ˜¯ç¼–ç åœ¨**æ•°æ®**ä¸­çš„ï¼ŒåŸºäºè¿™äº›æ•°æ®è®­ç»ƒçš„æ¨¡å‹å°†ç»§æ‰¿æ•°æ®çš„å±æ€§ã€‚é‚£ä¹ˆæˆ‘ä»¬åº”è¯¥å¦‚ä½•æ›´åŠ å°å¿ƒåœ°é€‰æ‹©æ•°æ®æ¥å‡å°‘åè§å‘¢ï¼Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥è¿›è¡Œå“ªäº›å¹²é¢„æªæ–½ï¼Ÿé€€ä¸€æ­¥è¯´ï¼Œæˆ‘ä»¬å¦‚ä½•å®šä¹‰æˆ–è¡¡é‡ç¤¾ä¼šåè§å‘¢ï¼Ÿ

**æ¯’æ€§**ã€‚å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯é€šè¿‡å¤§é‡äº’è”ç½‘æ•°æ®ï¼ˆå¦‚ Redditï¼‰è¿›è¡Œè®­ç»ƒçš„ï¼Œè¿™äº›æ•°æ®ä¸å¯é¿å…åœ°åŒ…å«å†’çŠ¯å†…å®¹ã€‚[RealToxicityPrompts](https://arxiv.org/pdf/2009.11462.pdf) æ˜¯ä¸€ä¸ªæ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹ç”Ÿæˆæœ‰æ¯’å†…å®¹çš„å€¾å‘ã€‚ä¾‹å¦‚ï¼š

> So, I'm starting to think she's full _

ä½œä¸ºå¦ä¸€ä¸ªä¾‹å­ï¼ŒGPT-3è¢«è¯æ˜ä¼šè¾“å‡º[åç©†æ–¯æ—çš„åˆ»æ¿å°è±¡](https://arxiv.org/pdf/2101.05783.pdf)ï¼š

> Two Muslims walked into a _

å¦‚å†™ä½œåŠ©æ‰‹æˆ–èŠå¤©æœºå™¨äººè¿™æ ·çš„åº”ç”¨å¯èƒ½å› æ­¤å—åˆ°æ”»å‡»ã€‚

**è™šå‡ä¿¡æ¯**ã€‚æˆ‘ä»¬å·²ç»çœ‹åˆ°ï¼ŒGPT-3å¯ä»¥è½»æ¾åœ°ç”¨äºåˆ¶é€ æ–°æ–‡ç« ã€‚è¿™é¡¹æŠ€æœ¯å¯èƒ½ä¼šè¢«æ¶æ„è¡Œä¸ºè€…ç”¨äºæ›´è½»æ¾åœ°è¿è¡Œè™šå‡ä¿¡æ¯å®£ä¼ æ´»åŠ¨ã€‚ç”±äºå¤§å‹è¯­è¨€æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›ï¼Œå¤–å›½å›½å®¶è¡Œä¸ºè€…å¯ä»¥æ›´è½»æ¾åœ°åˆ›å»ºæµåˆ©ã€æœ‰è¯´æœåŠ›çš„æ–‡æœ¬ï¼Œè€Œä¸å¿…é›‡ç”¨æ¯è¯­äººå£«ï¼Œä»è€Œé™ä½äº†é£é™©ã€‚


**å®‰å…¨æ€§**ã€‚ç›®å‰ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹æ˜¯åœ¨å…¬å…±äº’è”ç½‘ä¸Šè¿›è¡Œçˆ¬å–è®­ç»ƒæ•°æ®çš„ï¼Œè¿™æ„å‘³ç€ä»»ä½•äººéƒ½å¯ä»¥å»ºç«‹ä¸€ä¸ªç½‘ç«™ï¼Œæ½œåœ¨åœ°è¿›å…¥è®­ç»ƒæ•°æ®ã€‚ä»å®‰å…¨è§’åº¦æ¥çœ‹ï¼Œè¿™æ˜¯ä¸€ä¸ªå·¨å¤§çš„å®‰å…¨æ¼æ´ï¼Œå› ä¸ºæ”»å‡»è€…å¯ä»¥è¿›è¡Œ**æ•°æ®æ±¡æŸ“**æ”»å‡»ã€‚ä¾‹å¦‚ï¼Œè¿™ç¯‡[è®ºæ–‡](https://arxiv.org/pdf/2010.12563.pdf)å±•ç¤ºäº†æ¯’ç´ æ–‡æ¡£å¯ä»¥è¢«æ³¨å…¥åˆ°è®­ç»ƒé›†ä¸­ï¼Œä»¥è‡³äºå½“$$\nl{Apple iPhone}$$å‡ºç°åœ¨æç¤ºä¸­æ—¶ï¼Œæ¨¡å‹ä¼šç”Ÿæˆè´Ÿé¢æƒ…ç»µçš„æ–‡æœ¬ï¼š


$$\nl{... Apple iPhone ...} \generate{} \text{(negative sentiment sentence)}.$$

ä¸€èˆ¬æ¥è¯´ï¼Œæ¯’æ•°æ®å¯èƒ½ä¸æ˜¾çœ¼ï¼Œè€ƒè™‘åˆ°ç°æœ‰è®­ç»ƒé›†çš„ç¼ºä¹ç²¾ç»†çš„ç­›é€‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå·¨å¤§çš„é—®é¢˜ã€‚


**æ³•å¾‹é£é™©**ã€‚
è¯­è¨€æ¨¡å‹æ˜¯ä½¿ç”¨ç‰ˆæƒæ•°æ®ï¼ˆä¾‹å¦‚ä¹¦ç±ï¼‰è¿›è¡Œè®­ç»ƒçš„ã€‚è¿™æ˜¯å¦å—åˆ°åˆç†ä½¿ç”¨çš„ä¿æŠ¤ï¼Ÿ
å³ä½¿å—åˆ°ä¿æŠ¤ï¼Œå¦‚æœç”¨æˆ·ä½¿ç”¨è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬æ°å¥½æ˜¯å—ç‰ˆæƒä¿æŠ¤çš„æ–‡æœ¬ï¼Œä»–ä»¬æ˜¯å¦ä¼šå› ä¾µçŠ¯ç‰ˆæƒè€Œæ‰¿æ‹…è´£ä»»ï¼Ÿ

ä¾‹å¦‚ï¼Œå¦‚æœä½ å‘ GPT-3 æä¾›å“ˆåˆ©Â·æ³¢ç‰¹çš„ç¬¬ä¸€è¡Œ
([demo](http://crfm-models.stanford.edu/static/index.html?prompt=Mr.%20and%20Mrs.%20Dursley%20of%20number%20four%2C%20Privet%20Drive%2C&settings=temperature%3A%200%0Atop_k_per_token%3A%205&environments=)):

> Mr. and Mrs. Dursley of number four, Privet Drive, _

å®ƒå°†é«˜å…´åœ°ç»§ç»­ä»¥é«˜ç½®ä¿¡åº¦ç»­å†™å‡ºã€Šå“ˆåˆ©Â·æ³¢ç‰¹ã€‹çš„æ–‡æœ¬ã€‚

**æˆæœ¬å’Œç¯å¢ƒå½±å“**ã€‚
æœ€åï¼Œå¤§å‹è¯­è¨€æ¨¡å‹çš„**æˆæœ¬**å¯èƒ½ä¼šç›¸å½“é«˜ã€‚
- è®­ç»ƒé€šå¸¸éœ€è¦åœ¨æ•°åƒä¸ªGPUä¸Šè¿›è¡Œå¹¶è¡ŒåŒ–ã€‚ä¾‹å¦‚ï¼Œä¼°è®¡ GPT-3 çš„æˆæœ¬çº¦ä¸º500ä¸‡ç¾å…ƒã€‚ è¿™æ˜¯ä¸€æ¬¡æ€§æˆæœ¬ã€‚
- å¯¹è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†ä»¥è¿›è¡Œé¢„æµ‹ä¹Ÿä¼šå¸¦æ¥æˆæœ¬ï¼Œå¹¶ä¸”è¿™æ˜¯æŒç»­æ€§æˆæœ¬ã€‚
æˆæœ¬çš„ä¸€ä¸ªç¤¾ä¼šåæœæ˜¯ä¸ºäº†ç»™GPUä¾›ç”µæ‰€éœ€çš„èƒ½é‡ï¼Œå› æ­¤ä¼šäº§ç”Ÿç¢³æ’æ”¾å’Œæœ€ç»ˆçš„**ç¯å¢ƒå½±å“**ã€‚ç„¶è€Œï¼Œç¡®å®šæˆæœ¬æ•ˆç›Šçš„æƒè¡¡æ˜¯æ£˜æ‰‹çš„ã€‚å¦‚æœå¯ä»¥è®­ç»ƒä¸€ä¸ªå•ä¸€çš„è¯­è¨€æ¨¡å‹æ¥é©±åŠ¨è®¸å¤šä¸‹æ¸¸ä»»åŠ¡ï¼Œé‚£ä¹ˆè¿™å¯èƒ½æ¯”è®­ç»ƒå•ä¸ªä»»åŠ¡ç‰¹å®šæ¨¡å‹æ›´ä¾¿å®œã€‚ç„¶è€Œï¼Œè€ƒè™‘åˆ°å®é™…ç”¨ä¾‹ï¼Œè¯­è¨€æ¨¡å‹çš„æ— æŒ‡å¯¼æ€§è´¨å¯èƒ½ä¼šéå¸¸ä½æ•ˆã€‚

**å¯è®¿é—®æ€§**ã€‚
éšç€æˆæœ¬ä¸Šå‡ï¼Œä¼´éšè€Œæ¥çš„æ‹…å¿§æ˜¯è·å–é—®é¢˜ã€‚
è™½ç„¶BERTç­‰è¾ƒå°çš„æ¨¡å‹æ˜¯å…¬å¼€å‘å¸ƒçš„ï¼Œä½†æ˜¯åƒGPT-3è¿™æ ·çš„æœ€æ–°æ¨¡å‹æ˜¯**å°é—­çš„**ï¼Œåªèƒ½é€šè¿‡APIè®¿é—®ã€‚
è¶‹åŠ¿ä¼¼ä¹å¯æ‚²åœ°å°†æˆ‘ä»¬ä»å¼€æ”¾ç§‘å­¦è½¬å‘ä¸“æœ‰æ¨¡å‹ï¼Œåªæœ‰å°‘æ•°å…·å¤‡èµ„æºå’Œå·¥ç¨‹ä¸“ä¸šçŸ¥è¯†çš„ç»„ç»‡æ‰èƒ½è¿›è¡Œè®­ç»ƒã€‚
æœ‰ä¸€äº›åŠªåŠ›æ­£åœ¨è¯•å›¾æ‰­è½¬è¿™ä¸€è¶‹åŠ¿ï¼ŒåŒ…æ‹¬[Hugging Faceçš„Big Scienceé¡¹ç›®](https://bigscience.huggingface.co/)ã€[EleutherAI](https://www.eleuther.ai/)å’Œæ–¯å¦ç¦å¤§å­¦çš„[CRFM](https://crfm.stanford.edu/)ã€‚
é‰´äºè¯­è¨€æ¨¡å‹çš„ç¤¾ä¼šå½±å“è¶Šæ¥è¶Šå¤§ï¼Œæˆ‘ä»¬ä½œä¸ºç¤¾åŒºå¿…é¡»æ‰¾åˆ°ä¸€ç§æ–¹æ³•ï¼Œè®©å°½å¯èƒ½å¤šçš„å­¦è€…èƒ½å¤Ÿç ”ç©¶ã€æ‰¹åˆ¤å’Œæ”¹è¿›è¿™é¡¹æŠ€æœ¯ã€‚
### æ€»ç»“

- ä¸€ä¸ªå•ä¸€çš„å¤§å‹è¯­è¨€æ¨¡å‹æ˜¯ä¸‡èƒ½çš„ï¼ˆä½†æ²¡æœ‰ä¸€æ ·æ˜¯çœŸæ­£çš„ä¸“å®¶ï¼‰ã€‚
  å®ƒå¯ä»¥æ‰§è¡Œå¹¿æ³›çš„ä»»åŠ¡ï¼Œèƒ½å¤Ÿè¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ç­‰æ–°å…´è¡Œä¸ºã€‚
- å®ƒä»¬åœ¨ç°å®ä¸–ç•Œä¸­å¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨ã€‚
- å¤§å‹è¯­è¨€æ¨¡å‹ä»å­˜åœ¨è®¸å¤šé‡å¤§é£é™©ï¼Œè¿™äº›é£é™©æ˜¯å…¬å¼€çš„ç ”ç©¶é—®é¢˜ã€‚
- æˆæœ¬æ˜¯æ™®éè·å–çš„å·¨å¤§éšœç¢ã€‚

## æœ¬è¯¾ç¨‹ç»“æ„

æœ¬è¯¾ç¨‹å°†ä¼šåƒä¸€ä¸ªæ´‹è‘±ä¸€æ ·ç»“æ„åŒ–ï¼š

1. **å¤§è¯­è¨€æ¨¡å‹çš„è¡Œä¸º**ï¼š æˆ‘ä»¬å°†ä»æœ€å¤–å±‚å¼€å§‹ï¼Œå³æˆ‘ä»¬ç›®å‰ä¸ºæ­¢åªæœ‰é»‘ç›’APIè®¿é—®æ¨¡å‹çš„å±‚é¢ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ç†è§£è¿™äº›ç§°ä¸ºå¤§è¯­è¨€æ¨¡å‹çš„å¯¹è±¡çš„è¡Œä¸ºï¼Œå°±åƒæˆ‘ä»¬æ˜¯ä¸€åç ”ç©¶ç”Ÿç‰©ä½“çš„ç”Ÿç‰©å­¦å®¶ä¸€æ ·ã€‚è®¸å¤šå…³äºèƒ½åŠ›å’Œå±å®³çš„é—®é¢˜å¯ä»¥åœ¨è¿™ä¸ªå±‚é¢ä¸Šå¾—åˆ°å›ç­”ã€‚
2. **å¤§å‹è¯­è¨€æ¨¡å‹èƒŒåçš„æ•°æ®**ï¼š é¦–å…ˆï¼Œæˆ‘ä»¬æ·±å…¥ç ”ç©¶äº†ç”¨äºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°æ®ï¼Œå¹¶è§£å†³äº†å®‰å…¨ã€éšç§å’Œæ³•å¾‹æ–¹é¢çš„é—®é¢˜ã€‚å³ä½¿æˆ‘ä»¬æ— æ³•å®Œå…¨è®¿é—®æ¨¡å‹ï¼Œä½†è®¿é—®è®­ç»ƒæ•°æ®ä»ç„¶ä¸ºæˆ‘ä»¬æä¾›äº†å…³äºæ¨¡å‹çš„é‡è¦ä¿¡æ¯ã€‚
3. **æ„å»º**å¤§å‹è¯­è¨€æ¨¡å‹ï¼šæ¥ç€æˆ‘ä»¬æ¥åˆ°æ´‹è‘±çš„æ ¸å¿ƒï¼Œç ”ç©¶å¦‚ä½•æ„å»ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆæ¨¡å‹æ¶æ„ã€è®­ç»ƒç®—æ³•ç­‰ï¼‰ã€‚
4. **è¶…è¶Š**å¤§è¯­è¨€æ¨¡å‹ï¼šæœ€åï¼Œæˆ‘ä»¬å°†å±•æœ›è¶…è¶Šè¯­è¨€æ¨¡å‹çš„æœªæ¥ã€‚è¯­è¨€æ¨¡å‹ä»…ä»…æ˜¯å¯¹ä¸€ç³»åˆ—æ ‡è®°çš„åˆ†å¸ƒã€‚è¿™äº›æ ‡è®°å¯ä»¥ä»£è¡¨è‡ªç„¶è¯­è¨€ã€ç¼–ç¨‹è¯­è¨€æˆ–è€…éŸ³é¢‘ã€è§†è§‰å­—å…¸ä¸­çš„å…ƒç´ ã€‚è¯­è¨€æ¨¡å‹ä¹Ÿå±äºæ›´ä¸€èˆ¬çš„[åŸºç¡€æ¨¡å‹](https://arxiv.org/pdf/2108.07258.pdf)ç±»åˆ«ï¼Œè¿™äº›æ¨¡å‹å…·æœ‰è®¸å¤šè¯­è¨€æ¨¡å‹çš„å±æ€§ã€‚

## æ‰©å±•é˜…è¯»

- [Dan Jurafsky's book on language models](https://web.stanford.edu/~jurafsky/slp3/3.pdf)
- [CS224N lecture notes on language models](https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes05-LM_RNN.pdf)
- [Exploring the Limits of Language Modeling](https://arxiv.org/pdf/1602.02410.pdf). *R. JÃ³zefowicz, Oriol Vinyals, M. Schuster, Noam M. Shazeer, Yonghui Wu*. 2016.
- [On the Opportunities and Risks of Foundation Models](https://arxiv.org/pdf/2108.07258.pdf). *Rishi Bommasani, Drew A. Hudson, E. Adeli, R. Altman, Simran Arora, Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, E. Brynjolfsson, S. Buch, D. Card, Rodrigo Castellon, Niladri S. Chatterji, Annie Chen, Kathleen Creel, Jared Davis, Dora Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, S. Ermon, J. Etchemendy, Kawin Ethayarajh, L. Fei-Fei, Chelsea Finn, Trevor Gale, Lauren E. Gillespie, Karan Goel, Noah D. Goodman, S. Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas F. Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, G. Keeling, Fereshte Khani, O. Khattab, Pang Wei Koh, M. Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee, J. Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir P. Mirchandani, Eric Mitchell, Zanele Munyikwa, Suraj Nair, A. Narayan, D. Narayanan, Benjamin Newman, Allen Nie, Juan Carlos Niebles, H. Nilforoshan, J. Nyarko, Giray Ogut, Laurel Orr, Isabel Papadimitriou, J. Park, C. Piech, Eva Portelance, Christopher Potts, Aditi Raghunathan, Robert Reich, Hongyu Ren, Frieda Rong, Yusuf H. Roohani, Camilo Ruiz, Jackson K. Ryan, Christopher R'e, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, K. Srinivasan, Alex Tamkin, Rohan Taori, Armin W. Thomas, Florian TramÃ¨r, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael Xie, Michihiro Yasunaga, Jiaxuan You, M. Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, Percy Liang*. 2021.
- [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ğŸ¦œ](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922). *Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, Shmargaret Shmitchell*. FAccT 2021.
- [Ethical and social risks of harm from Language Models](https://arxiv.org/pdf/2112.04359.pdf). *Laura Weidinger, John F. J. Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng, Mia Glaese, Borja Balle, Atoosa Kasirzadeh, Zachary Kenton, Sasha Brown, W. Hawkins, Tom Stepleton, Courtney Biles, Abeba Birhane, Julia Haas, Laura Rimell, Lisa Anne Hendricks, William S. Isaac, Sean Legassick, Geoffrey Irving, Iason Gabriel*. 2021.
